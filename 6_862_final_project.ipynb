{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.862_final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f4d4e140e9341628c47594ff7ce93b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc73262d0df543689e5f74b911cc6ba6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4fbee3d4f2fd41d191506e31e4d4682d",
              "IPY_MODEL_42864d7f17ae4013a00833d132762ab2"
            ]
          }
        },
        "dc73262d0df543689e5f74b911cc6ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fbee3d4f2fd41d191506e31e4d4682d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a28baa07b554626adfe08f7a0f77b41",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78b0e0acebcc458093de4afc8c87f944"
          }
        },
        "42864d7f17ae4013a00833d132762ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4325c06ca4fc480a8f98c39217b25f20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:02&lt;00:00, 85.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88f5aac8278246489fc247e3ec132ae2"
          }
        },
        "0a28baa07b554626adfe08f7a0f77b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78b0e0acebcc458093de4afc8c87f944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4325c06ca4fc480a8f98c39217b25f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88f5aac8278246489fc247e3ec132ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2e16ca993ff43dc910263a1c0c7c367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40c26ce6a2364ccd8de662cada80fc19",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_13d92a54e50b44d5902d7c65d114659e",
              "IPY_MODEL_6c80f85be92245f799ddd26d78cf8c71"
            ]
          }
        },
        "40c26ce6a2364ccd8de662cada80fc19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13d92a54e50b44d5902d7c65d114659e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b12219354b44e4a8d2fe95ca9ae6fa9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63a46bc98d054fb59dbd88af48b84b70"
          }
        },
        "6c80f85be92245f799ddd26d78cf8c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e7e6d5e6bc3458cb8dda3ca7c4c5558",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 47.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1c378f214d247809e7f3d9ecd477820"
          }
        },
        "0b12219354b44e4a8d2fe95ca9ae6fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63a46bc98d054fb59dbd88af48b84b70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e7e6d5e6bc3458cb8dda3ca7c4c5558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1c378f214d247809e7f3d9ecd477820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c8c77e9988e4f98b54d215e8f1eca8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32a7cf9e0b7848ef8fba146183e5a958",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_22d226f1ee0843808c5c36a2146cfeea",
              "IPY_MODEL_0f9c997de25a4d309fc3e38a2c12709b"
            ]
          }
        },
        "32a7cf9e0b7848ef8fba146183e5a958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22d226f1ee0843808c5c36a2146cfeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d1da68f1b364cf1b411657149c058a7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56c4f7d594024747a0498c4ff51134e0"
          }
        },
        "0f9c997de25a4d309fc3e38a2c12709b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbf59f8632764411b2f530112dba6a11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 976kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd2e209c9b1d4f448df3929fb258be88"
          }
        },
        "2d1da68f1b364cf1b411657149c058a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56c4f7d594024747a0498c4ff51134e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbf59f8632764411b2f530112dba6a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd2e209c9b1d4f448df3929fb258be88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95e8f217619943abab4fdb718c8ed667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_22068f0561c94969b8ca268690a32f12",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e673352580654eb9a74bf22129c6bd42",
              "IPY_MODEL_0215eecbdb9a4773b21086e15387c52b"
            ]
          }
        },
        "22068f0561c94969b8ca268690a32f12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e673352580654eb9a74bf22129c6bd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ef9dcfc74884f90a6ad9db78c3632ae",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 526681800,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 526681800,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_881d1aa94b7145e9ba0e1c439b59d4d8"
          }
        },
        "0215eecbdb9a4773b21086e15387c52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a82f28c3cca34a4b9f14c76f4055cfc0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 527M/527M [00:09&lt;00:00, 58.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_770151171cf14dd6a0236cf802c39b93"
          }
        },
        "9ef9dcfc74884f90a6ad9db78c3632ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "881d1aa94b7145e9ba0e1c439b59d4d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a82f28c3cca34a4b9f14c76f4055cfc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "770151171cf14dd6a0236cf802c39b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6UpxVZHbFwn"
      },
      "source": [
        "# Import Necessary Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNjEsPJ-UGtW"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, \\\n",
        "                            TimeDistributed, LSTM, Dropout, Bidirectional, \\\n",
        "                            Conv1D, BatchNormalization\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import TFBertForTokenClassification, AdamW\n",
        "\n",
        "plt.style.use(\"tableau-colorblind10\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsmoQ3SrtVJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b892d9-e913-4b5f-8202-931958e29786"
      },
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0d6SLrgtiDK"
      },
      "source": [
        "os.chdir('drive/MyDrive/MIT_6.862/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEG3GPhJTI22"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/MIT_6.862/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NlLWjRETIJ-"
      },
      "source": [
        "from metrics.ner_evaluation.ner_eval import collect_named_entities\n",
        "from metrics.ner_evaluation.ner_eval import compute_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Tsr3goibUnD"
      },
      "source": [
        "# Load data and EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Ds_FwsZLA-"
      },
      "source": [
        "data = pd.read_csv('NER_data/ner_dataset.csv', encoding=\"latin1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "nNBZfyc0edT2",
        "outputId": "640dd9ad-59f2-42c7-ec65-515255590233"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>47959</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>47959</td>\n",
              "      <td>35178</td>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Sentence: 40496</td>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>52573</td>\n",
              "      <td>145807</td>\n",
              "      <td>887908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Sentence #     Word      POS      Tag\n",
              "count             47959  1048575  1048575  1048575\n",
              "unique            47959    35178       42       17\n",
              "top     Sentence: 40496      the       NN        O\n",
              "freq                  1    52573   145807   887908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATLmvXqJegHF",
        "outputId": "a5ffc6f2-b3f4-47a1-e719-e513173ca840"
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    object\n",
              "Word          object\n",
              "POS           object\n",
              "Tag           object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "avb-_5fiZCsb",
        "outputId": "71666ebf-8f58-4faf-eefb-554f6bb6bc4e"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo85NaYBaYiy"
      },
      "source": [
        "# fill in the empty positions in column Sentence #\n",
        "sentence_sep = data['Sentence #'].isna()\n",
        "for i in range(data.shape[0]):\n",
        "    if sentence_sep[i]:\n",
        "        data.iloc[i,0] = data.iloc[i-1,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-98_0ltxhRNk"
      },
      "source": [
        "# save imputed dataset to csv\n",
        "data.to_csv('NER_data/ner_dataset_fill.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkmZJe2Rlgkv"
      },
      "source": [
        "## Start to run from here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acMTy4pklXHW"
      },
      "source": [
        "# read in imputed dataset\n",
        "df = pd.read_csv('NER_data/ner_dataset_fill.csv', index_col=False, encoding=\"latin1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "lOz7WjktmGGh",
        "outputId": "d160ab42-52d2-4225-8554-ad477535c174"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l99hJuJ7m5j0",
        "outputId": "1e42925e-1a02-427b-f6c2-fd85b78d023a"
      },
      "source": [
        "# check if there are any NAs left\n",
        "df.isna().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    False\n",
              "Word          False\n",
              "POS           False\n",
              "Tag           False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMdhLvsZlpPa"
      },
      "source": [
        "# Create unique word list, store the list and its length\n",
        "words = sorted(df['Word'].unique())\n",
        "words.append('ENDPAD')\n",
        "words_size = len(words)\n",
        "\n",
        "# Create unique tag list, store the list and its length\n",
        "tags = sorted(df['Tag'].unique())\n",
        "tags.append('PAD')\n",
        "tags_size = len(tags)\n",
        "\n",
        "# Create two dictionaries word:word_idx and word_idx:word\n",
        "word2idx = {value: count for count, value in enumerate(words)}\n",
        "idx2word = {count: value for value, count in word2idx.items()}\n",
        "\n",
        "# Create two dictionaries tag:tag_idx and tag_idx:tag\n",
        "tag2idx = {value: count for count, value in enumerate(tags)}\n",
        "idx2tag = {count: value for value, count in tag2idx.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KJ9JA6byRGL",
        "outputId": "d484fc42-1e8c-4320-be68-371433620f45"
      },
      "source": [
        "# create list of list where each inner list is the list of word for each sentences\n",
        "# create list of list where each inner list is the list of tag for each sentences\n",
        "sentence_group = df.groupby('Sentence #')\n",
        "sentence_list = []\n",
        "tag_list = []\n",
        "count = 1\n",
        "for sen in sentence_group.groups.keys():\n",
        "    if count % 5000 == 0:\n",
        "        print(f'iter: {count}')\n",
        "    count += 1\n",
        "    df_group = sentence_group.get_group(sen)\n",
        "    sentence_list.append(df_group['Word'].tolist())\n",
        "    tag_list.append(df_group['Tag'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter: 5000\n",
            "iter: 10000\n",
            "iter: 15000\n",
            "iter: 20000\n",
            "iter: 25000\n",
            "iter: 30000\n",
            "iter: 35000\n",
            "iter: 40000\n",
            "iter: 45000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AwZfJD-06Ex",
        "outputId": "c4bf5f36-03ff-4d5c-ed5c-bc541be04522"
      },
      "source": [
        "# pick the appropriate sentence length. Here we want to make sure that the majority of our sentences is shorter than our picked length.\n",
        "# evectually we land on the 99.75% percentile.\n",
        "max_length = int(np.percentile([len(sen) for sen in sentence_list], 99.75))\n",
        "num_long_length = len([sen for sen in sentence_list if len(sen) > 40])\n",
        "print(f'Picked max length for one sentence: {max_length}')\n",
        "print(f'Number of sentences being trimmed: {num_long_length}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Picked max length for one sentence: 50\n",
            "Number of sentences being trimmed: 772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7OZLyfrMqsx"
      },
      "source": [
        "# set max_length\n",
        "max_length = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AncWxAD3Of_5"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJFliV0rKWoW"
      },
      "source": [
        "# split train-test with ratio 0.1\n",
        "sent_tr, sent_te, tag_tr, tag_te = train_test_split(sentence_list, tag_list, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAVBsU75PpgN"
      },
      "source": [
        "## LSTM Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0T1V_Dazm0u"
      },
      "source": [
        "# create list of list where each inner list is the list of word indices for each sentences\n",
        "# create list of list where each inner list is the list of tag indices for each sentences\n",
        "X_tr = []\n",
        "y_tr = []\n",
        "for i in range(len(sent_tr)):\n",
        "    X_tr.append(list(map(word2idx.get, sent_tr[i])))\n",
        "    y_tr.append(list(map(tag2idx.get, tag_tr[i])))\n",
        "\n",
        "X_te = []\n",
        "y_te = []\n",
        "for i in range(len(sent_te)):\n",
        "    X_te.append(list(map(word2idx.get, sent_te[i])))\n",
        "    y_te.append(list(map(tag2idx.get, tag_te[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahwtu2bE2-0U"
      },
      "source": [
        "# pad both our X and y \n",
        "X_tr_pad = pad_sequences(sequences = X_tr, maxlen = max_length, padding = 'post', value = word2idx['ENDPAD'])\n",
        "y_tr_pad = pad_sequences(sequences = y_tr, maxlen = max_length, padding = 'post', value = tag2idx[\"PAD\"])\n",
        "\n",
        "X_te_pad = pad_sequences(sequences = X_te, maxlen = max_length, padding = 'post', value = word2idx['ENDPAD'])\n",
        "y_te_pad = pad_sequences(sequences = y_te, maxlen = max_length, padding = 'post', value = tag2idx[\"PAD\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1DAW16ArjSY",
        "outputId": "2f41b4d9-c014-430b-e27c-b3d3094d4838"
      },
      "source": [
        "# examine class imbalance in training data\n",
        "s, count = np.unique(list(np.concatenate(y_tr_pad).flat), return_counts=True)\n",
        "print(pd.DataFrame(count, index = tags, columns = ['Count']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Count\n",
            "B-art      355\n",
            "B-eve      272\n",
            "B-geo    33836\n",
            "B-gpe    14267\n",
            "B-nat      179\n",
            "B-org    18075\n",
            "B-per    15311\n",
            "B-tim    18285\n",
            "I-art      257\n",
            "I-eve      213\n",
            "I-geo     6697\n",
            "I-gpe      182\n",
            "I-nat       42\n",
            "I-org    15075\n",
            "I-per    15584\n",
            "I-tim     5931\n",
            "O       798806\n",
            "PAD    1214783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ5kixgmzRb-",
        "outputId": "a25b53e1-ec22-4329-a639-55754d97a632"
      },
      "source": [
        "# calculate average count per class\n",
        "np.mean(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119897.22222222222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlBWO8yvqU7k"
      },
      "source": [
        "# one hot encode our target variable\n",
        "y_tr_pad = to_categorical(y_tr_pad, num_classes=tags_size)\n",
        "\n",
        "y_te_pad = to_categorical(y_te_pad, num_classes=tags_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MO8erkpHP9c"
      },
      "source": [
        "## Build Bidirectional LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhRgrgS7IqY-"
      },
      "source": [
        "# set parameters for Bidirectional LSTM\n",
        "n_units = 100\n",
        "drop_rate = .1\n",
        "dim_embed = 50\n",
        "\n",
        "optimizer = \"rmsprop\"\n",
        "metrics = ['categorical_accuracy']\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "validation_split = 0.1\n",
        "verbose = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKyoVvS_gE2p"
      },
      "source": [
        "# calculate potential class weights for loss based on class imbalance\n",
        "# didn't use this part eventually\n",
        "y_tr_int = np.argmax(y_tr_pad, axis=2).flatten()\n",
        "class_weights = compute_class_weight('balanced', np.unique(y_tr_int), y_tr_int)\n",
        "class_weights = np.asarray(class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaATzl2Abdp2"
      },
      "source": [
        "# to calculate the standard categorical cross entropy, we set the class weight to all ones\n",
        "weights = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W9FrAmqbWWv"
      },
      "source": [
        "# define a custom loss function that combines class weights with categorical cross entropy loss\n",
        "def custom_loss(y_true, y_pred):\n",
        "\n",
        "  # get the first two dimensions from y_pred\n",
        "  if y_pred.shape[0] is None:\n",
        "    x = 1\n",
        "  else:\n",
        "    x = int(y_pred.shape[0])\n",
        "  y = y_pred.shape[1]\n",
        "\n",
        "  # reshape weight for each batch\n",
        "  batch_weights = np.array([np.array(weights)] * (x*y))\n",
        "  batch_weights = batch_weights.reshape(x,y,18)\n",
        "  batch_weights = tf.cast(batch_weights, tf.float64)\n",
        "\n",
        "  # cast y_true and y_pred into tf.float64\n",
        "  y_true = tf.cast(y_true, tf.float64)\n",
        "  y_pred = tf.cast(y_pred, tf.float64)\n",
        "\n",
        "  # return weighted categorical cross entropy\n",
        "  return tf.math.reduce_sum(y_true * batch_weights, axis=-1) * tf.keras.losses.categorical_crossentropy(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBSvIjC_3_K8"
      },
      "source": [
        "# Build BiLSTM model\n",
        "model_title = \"BiLSTM\"\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    Embedding(\n",
        "        input_dim = words_size, output_dim = dim_embed, input_length = max_length\n",
        "    )\n",
        ")\n",
        "model.add(Dropout(drop_rate))\n",
        "model.add(Bidirectional(LSTM(n_units, return_sequences = True)))\n",
        "model.add(TimeDistributed(Dense(tags_size, activation = 'softmax')))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=optimizer, loss=custom_loss, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyoIJgi4mUCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8fd358c-f8c2-4a1c-92a2-8e3fe0af0dae"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 50, 50)            1758950   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50, 50)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 50, 200)           120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 50, 18)            3618      \n",
            "=================================================================\n",
            "Total params: 1,883,368\n",
            "Trainable params: 1,883,368\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwUHY9vARMqz"
      },
      "source": [
        "# set early stopping for model\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto'\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztk1y9rJKPdj",
        "outputId": "f6ba5d8b-2745-4104-f1e7-36dc3f6d0268"
      },
      "source": [
        "# fit the model\n",
        "history = model.fit(X_tr_pad, y_tr_pad, batch_size=batch_size, epochs=epochs, \n",
        "                  validation_split=validation_split, callbacks=callbacks, verbose=verbose)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1214/1214 [==============================] - 18s 15ms/step - loss: 0.0289 - categorical_accuracy: 0.9914 - val_loss: 0.0487 - val_categorical_accuracy: 0.9855\n",
            "Epoch 2/20\n",
            "1214/1214 [==============================] - 21s 17ms/step - loss: 0.0272 - categorical_accuracy: 0.9918 - val_loss: 0.0498 - val_categorical_accuracy: 0.9852\n",
            "Epoch 3/20\n",
            "1214/1214 [==============================] - 21s 17ms/step - loss: 0.0255 - categorical_accuracy: 0.9923 - val_loss: 0.0509 - val_categorical_accuracy: 0.9851\n",
            "Epoch 4/20\n",
            "1214/1214 [==============================] - 21s 17ms/step - loss: 0.0239 - categorical_accuracy: 0.9927 - val_loss: 0.0512 - val_categorical_accuracy: 0.9855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eqnSdQSLRXs",
        "outputId": "447ec539-3927-451c-a8ed-bbacfce55171"
      },
      "source": [
        "# Examine performance for  \n",
        "y_pred = model.predict(X_te_pad, batch_size = batch_size, verbose = verbose)\n",
        "y_pred_flat = np.argmax(y_pred, axis = 2).flatten()\n",
        "y_te_flat = np.argmax(y_te_pad, axis = 2).flatten()\n",
        "\n",
        "# display f1 score for each class and \n",
        "f1 = f1_score(y_te_flat, y_pred_flat, average = None)\n",
        "print(pd.DataFrame(f1, index = tags))\n",
        "print('Mean F1 across classes: ',np.mean(f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 1s 4ms/step\n",
            "              0\n",
            "B-art  0.071429\n",
            "B-eve  0.360656\n",
            "B-geo  0.877252\n",
            "B-gpe  0.949495\n",
            "B-nat  0.285714\n",
            "B-org  0.741671\n",
            "B-per  0.839132\n",
            "B-tim  0.898318\n",
            "I-art  0.000000\n",
            "I-eve  0.197183\n",
            "I-geo  0.803419\n",
            "I-gpe  0.666667\n",
            "I-nat  0.250000\n",
            "I-org  0.765287\n",
            "I-per  0.869072\n",
            "I-tim  0.765018\n",
            "O      0.990918\n",
            "PAD    1.000000\n",
            "Mean F1 across classes:  0.6295127563298624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYF0X9Lx8ZQK"
      },
      "source": [
        "### Entity-level for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP9vWye08n7S"
      },
      "source": [
        "def make_precision_recall(entity_level_dict, scheme):\n",
        "  bert_entity_result = {}\n",
        "  for tag in entity_level_dict.keys():\n",
        "    if tag not in bert_entity_result.keys():\n",
        "      bert_entity_result[tag] = {}\n",
        "    bert_entity_result[tag]['precision'] = entity_level_dict[tag][scheme]['correct'] / entity_level_dict[tag][scheme]['actual'] \n",
        "    bert_entity_result[tag]['recall'] = entity_level_dict[tag][scheme]['correct'] / entity_level_dict[tag][scheme]['possible']\n",
        "    if bert_entity_result[tag]['recall'] + bert_entity_result[tag]['precision'] != 0:\n",
        "      bert_entity_result[tag]['f1'] = 2 * bert_entity_result[tag]['precision'] * bert_entity_result[tag]['recall'] / (bert_entity_result[tag]['recall'] + bert_entity_result[tag]['precision'])\n",
        "    else:\n",
        "      bert_entity_result[tag]['f1'] = 0\n",
        "  return bert_entity_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KApgBXSN9Meg"
      },
      "source": [
        "lstm_pred = np.argmax(y_pred, axis = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMhlVd5m8pkb"
      },
      "source": [
        "lstm_pred_tag = []\n",
        "y_true_tag_lstm = []\n",
        "y_true_te = te_tags.numpy()\n",
        "\n",
        "for i in range(len(bert_pred)):\n",
        "  lstm_pred_tag.append(list(map(idx2tag.get, lstm_pred[i])))\n",
        "  y_true_tag_lstm.append(list(map(idx2tag.get, y_true_te[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5AYsIxs8xM2"
      },
      "source": [
        "entity_tag = ['art', 'eve', 'geo', 'gpe', 'nat', 'org', 'per', 'tim']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRM257bH80ph"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "metrics_results = {'correct': 0, 'incorrect': 0, 'partial': 0,\n",
        "                   'missed': 0, 'spurious': 0, 'possible': 0, 'actual': 0, 'precision': 0,'recall': 0,}\n",
        "\n",
        "# overall results\n",
        "results = {'strict': deepcopy(metrics_results),\n",
        "           'ent_type': deepcopy(metrics_results),\n",
        "           \n",
        "           }\n",
        "\n",
        "# results aggregated by entity type\n",
        "evaluation_agg_entities_type_lstm = {e: deepcopy(results) for e in entity_tag}\n",
        "\n",
        "for true_ents, pred_ents in zip(y_true_tag_lstm, lstm_pred_tag):    \n",
        "    # compute results for one message\n",
        "    tmp_results, tmp_agg_results = compute_metrics(collect_named_entities(true_ents),collect_named_entities(pred_ents), entity_tag)\n",
        "\n",
        "    # aggregate overall results\n",
        "    for eval_schema in results.keys():\n",
        "        for metric in metrics_results.keys():\n",
        "            results[eval_schema][metric] += tmp_results[eval_schema][metric]\n",
        "\n",
        "\n",
        "    # aggregate results by entity type\n",
        "    for e_type in entity_tag:\n",
        "        for eval_schema in evaluation_agg_entities_type_lstm[e_type]:\n",
        "            for metric in tmp_agg_results[e_type][eval_schema]:\n",
        "                evaluation_agg_entities_type_lstm[e_type][eval_schema][metric] += tmp_agg_results[e_type][eval_schema][metric]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhDwodOV89Wt",
        "outputId": "21969f0a-4f98-4536-bcef-7dbf98d6aa9e"
      },
      "source": [
        "make_precision_recall(evaluation_agg_entities_type_lstm,'strict')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'art': {'f1': 0.000319744204636291,\n",
              "  'precision': 0.00016225864027259452,\n",
              "  'recall': 0.010869565217391304},\n",
              " 'eve': {'f1': 0.0012896985329679186,\n",
              "  'precision': 0.0006492452523940919,\n",
              "  'recall': 0.09523809523809523},\n",
              " 'geo': {'f1': 0.21846110083914094,\n",
              "  'precision': 0.19393939393939394,\n",
              "  'recall': 0.25008140670791273},\n",
              " 'gpe': {'f1': 0.1907018731663281,\n",
              "  'precision': 0.11940087607743394,\n",
              "  'recall': 0.4733893557422969},\n",
              " 'nat': {'f1': 0.0006474587245063129,\n",
              "  'precision': 0.00032499187520311994,\n",
              "  'recall': 0.08333333333333333},\n",
              " 'org': {'f1': 0.11816757304820721,\n",
              "  'precision': 0.08908964558721334,\n",
              "  'recall': 0.17542419266557197},\n",
              " 'per': {'f1': 0.0613280845333057,\n",
              "  'precision': 0.04314239906719137,\n",
              "  'recall': 0.10601719197707736},\n",
              " 'tim': {'f1': 0.14770240700218817,\n",
              "  'precision': 0.09765625,\n",
              "  'recall': 0.30296229802513464}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyRUQHNH7zXZ"
      },
      "source": [
        "## Build BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c8TzOwK74ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664,
          "referenced_widgets": [
            "7f4d4e140e9341628c47594ff7ce93b4",
            "dc73262d0df543689e5f74b911cc6ba6",
            "4fbee3d4f2fd41d191506e31e4d4682d",
            "42864d7f17ae4013a00833d132762ab2",
            "0a28baa07b554626adfe08f7a0f77b41",
            "78b0e0acebcc458093de4afc8c87f944",
            "4325c06ca4fc480a8f98c39217b25f20",
            "88f5aac8278246489fc247e3ec132ae2",
            "f2e16ca993ff43dc910263a1c0c7c367",
            "40c26ce6a2364ccd8de662cada80fc19",
            "13d92a54e50b44d5902d7c65d114659e",
            "6c80f85be92245f799ddd26d78cf8c71",
            "0b12219354b44e4a8d2fe95ca9ae6fa9",
            "63a46bc98d054fb59dbd88af48b84b70",
            "7e7e6d5e6bc3458cb8dda3ca7c4c5558",
            "e1c378f214d247809e7f3d9ecd477820",
            "3c8c77e9988e4f98b54d215e8f1eca8d",
            "32a7cf9e0b7848ef8fba146183e5a958",
            "22d226f1ee0843808c5c36a2146cfeea",
            "0f9c997de25a4d309fc3e38a2c12709b",
            "2d1da68f1b364cf1b411657149c058a7",
            "56c4f7d594024747a0498c4ff51134e0",
            "cbf59f8632764411b2f530112dba6a11",
            "cd2e209c9b1d4f448df3929fb258be88"
          ]
        },
        "outputId": "47a7ff5f-b220-4e45-afd4-ccb73900e0d2"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 18:47:06 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
            "2021-04-18 18:47:06 urllib3.connectionpool DEBUG: https://huggingface.co:443 \"HEAD /bert-base-cased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "2021-04-18 18:47:06 filelock DEBUG: Attempting to acquire lock 140143977945040 on /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
            "2021-04-18 18:47:06 filelock INFO: Lock 140143977945040 acquired on /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
            "2021-04-18 18:47:06 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
            "2021-04-18 18:47:06 urllib3.connectionpool DEBUG: https://huggingface.co:443 \"GET /bert-base-cased/resolve/main/vocab.txt HTTP/1.1\" 200 213450\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f4d4e140e9341628c47594ff7ce93b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 18:47:07 filelock DEBUG: Attempting to release lock 140143977945040 on /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
            "2021-04-18 18:47:07 filelock INFO: Lock 140143977945040 released on /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
            "2021-04-18 18:47:07 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 18:47:07 urllib3.connectionpool DEBUG: https://huggingface.co:443 \"HEAD /bert-base-cased/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
            "2021-04-18 18:47:07 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
            "2021-04-18 18:47:07 urllib3.connectionpool DEBUG: https://huggingface.co:443 \"HEAD /bert-base-cased/resolve/main/special_tokens_map.json HTTP/1.1\" 404 0\n",
            "2021-04-18 18:47:07 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
            "2021-04-18 18:47:07 urllib3.connectionpool DEBUG: https://huggingface.co:443 \"HEAD /bert-base-cased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "2021-04-18 18:47:07 filelock DEBUG: Attempting to acquire lock 140142290720016 on /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
            "2021-04-18 18:47:07 filelock INFO: Lock 140142290720016 acquired on /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
            "2021-04-18 18:47:07 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
            "2021-04-18 18:47:08 urllib3.connectionpool DEBUG: https://huggingface.co:443 \"GET /bert-base-cased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 29\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2e16ca993ff43dc910263a1c0c7c367",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 18:47:08 filelock DEBUG: Attempting to release lock 140142290720016 on /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
            "2021-04-18 18:47:08 filelock INFO: Lock 140142290720016 released on /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
            "2021-04-18 18:47:08 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 18:47:08 urllib3.connectionpool DEBUG: https://huggingface.co:443 \"HEAD /bert-base-cased/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
            "2021-04-18 18:47:08 filelock DEBUG: Attempting to acquire lock 140142837075280 on /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6.lock\n",
            "2021-04-18 18:47:08 filelock INFO: Lock 140142837075280 acquired on /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6.lock\n",
            "2021-04-18 18:47:08 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
            "2021-04-18 18:47:08 urllib3.connectionpool DEBUG: https://huggingface.co:443 \"GET /bert-base-cased/resolve/main/tokenizer.json HTTP/1.1\" 200 435797\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c8c77e9988e4f98b54d215e8f1eca8d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 18:47:09 filelock DEBUG: Attempting to release lock 140142837075280 on /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6.lock\n",
            "2021-04-18 18:47:09 filelock INFO: Lock 140142837075280 released on /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfZ3LE4eTuTo"
      },
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hCTaJ5xUHHq"
      },
      "source": [
        "tokenized_texts_and_labels_tr = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(sent_tr, tag_tr)\n",
        "]\n",
        "\n",
        "tokenized_texts_and_labels_te = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(sent_te, tag_te)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtnIoZqTWTZL"
      },
      "source": [
        "tokenized_texts_tr = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels_tr]\n",
        "labels_tr = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels_tr]\n",
        "\n",
        "tokenized_texts_te = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels_te]\n",
        "labels_te = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels_te]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR7U63XRXcnL"
      },
      "source": [
        "tr_inputs = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts_tr],\n",
        "                          maxlen=max_length, dtype=\"long\", value=word2idx['ENDPAD'],\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "te_inputs = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts_te],\n",
        "                          maxlen=max_length, dtype=\"long\", value=word2idx['ENDPAD'],\n",
        "                          truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cpzJkm9YFBr"
      },
      "source": [
        "tr_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels_tr],\n",
        "                     maxlen=max_length, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "te_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels_te],\n",
        "                     maxlen=max_length, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iya47bT1Yi1H"
      },
      "source": [
        "tr_masks = [[float(i != word2idx['ENDPAD']) for i in ii] for ii in tr_inputs]\n",
        "\n",
        "te_masks = [[float(i != word2idx['ENDPAD']) for i in ii] for ii in te_inputs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhp-p9GdYj40"
      },
      "source": [
        "tr_inputs = tf.convert_to_tensor(tr_inputs)\n",
        "te_inputs = tf.convert_to_tensor(te_inputs)\n",
        "tr_tags = tf.convert_to_tensor(tr_tags)\n",
        "te_tags = tf.convert_to_tensor(te_tags)\n",
        "tr_masks = tf.convert_to_tensor(tr_masks)\n",
        "te_masks = tf.convert_to_tensor(te_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhArhSQPbHhG",
        "outputId": "e639bb69-e43b-464a-a333-ee563e02d4d4"
      },
      "source": [
        "tr_masks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(43163, 50), dtype=float32, numpy=\n",
              "array([[1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcEVUnHQbIdT"
      },
      "source": [
        "# train_data = tf.data.Dataset(tr_inputs, tr_masks, tr_tags)\n",
        "# train_sampler = RandomSampler(train_data)\n",
        "# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "# valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "# valid_sampler = SequentialSampler(valid_data)\n",
        "# valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLFs72uNcAlp"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices(((tr_inputs, \n",
        "                                                  tr_masks), \n",
        "                                                 tr_tags))\n",
        "\n",
        "val_data = tf.data.Dataset.from_tensor_slices(((te_inputs, \n",
        "                                                  te_masks), \n",
        "                                               te_tags))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FABXNX9zkt1S",
        "outputId": "48861596-113e-48bf-da80-529e958c27d2"
      },
      "source": [
        "te_tags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4796, 50), dtype=int64, numpy=\n",
              "array([[16, 16, 16, ..., 17, 17, 17],\n",
              "       [16, 16, 16, ..., 16, 16, 16],\n",
              "       [16, 16, 16, ..., 17, 17, 17],\n",
              "       ...,\n",
              "       [16,  6, 14, ..., 17, 17, 17],\n",
              "       [16, 16, 16, ..., 17, 17, 17],\n",
              "       [ 6, 14, 14, ..., 17, 17, 17]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zr7Niz8e6lA",
        "outputId": "07a4514a-1c23-4297-843a-f50563ce2d35"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "TRAIN_SHUFFLE_BUFFER_SIZE = len(tr_tags)\n",
        "VAL_SHUFFLE_BUFFER_SIZE = len(te_tags)\n",
        "PREFETCH_BUFFER_SIZE = 100\n",
        "\n",
        "# Transfer training data\n",
        "train_data = train_data.shuffle(buffer_size=TRAIN_SHUFFLE_BUFFER_SIZE)\n",
        "train_data = train_data.batch(batch_size=BATCH_SIZE)\n",
        "train_data = train_data.prefetch(buffer_size=PREFETCH_BUFFER_SIZE)\n",
        "\n",
        "# Transfer validation data\n",
        "val_data = val_data.batch(batch_size=BATCH_SIZE)\n",
        "val_data = val_data.prefetch(buffer_size=PREFETCH_BUFFER_SIZE)\n",
        "\n",
        "print('train_data: ', train_data)\n",
        "print('val_data: ', val_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data:  <PrefetchDataset shapes: (((None, 50), (None, 50)), (None, 50)), types: ((tf.int64, tf.float32), tf.int64)>\n",
            "val_data:  <PrefetchDataset shapes: (((None, 50), (None, 50)), (None, 50)), types: ((tf.int64, tf.float32), tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315,
          "referenced_widgets": [
            "95e8f217619943abab4fdb718c8ed667",
            "22068f0561c94969b8ca268690a32f12",
            "e673352580654eb9a74bf22129c6bd42",
            "0215eecbdb9a4773b21086e15387c52b",
            "9ef9dcfc74884f90a6ad9db78c3632ae",
            "881d1aa94b7145e9ba0e1c439b59d4d8",
            "a82f28c3cca34a4b9f14c76f4055cfc0",
            "770151171cf14dd6a0236cf802c39b93"
          ]
        },
        "id": "ShqUD2_gffUS",
        "outputId": "5a9bc7e5-8426-480e-a510-88a02b5b8b64"
      },
      "source": [
        "model = TFBertForTokenClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels=len(tag2idx),\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 19:45:43 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
            "2021-04-18 19:45:43 urllib3.connectionpool DEBUG: https://huggingface.co:443 \"HEAD /bert-base-cased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "2021-04-18 19:45:43 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
            "2021-04-18 19:45:44 urllib3.connectionpool DEBUG: https://huggingface.co:443 \"HEAD /bert-base-cased/resolve/main/tf_model.h5 HTTP/1.1\" 302 0\n",
            "2021-04-18 19:45:44 filelock DEBUG: Attempting to acquire lock 140139546855376 on /root/.cache/huggingface/transformers/01800f4158e284e2447020e0124bc3f6aea3ac49848e744594f7cce8ee5ac0a4.a7137b2090d9302d722735af604b4c142ec9d1bfc31be7cbbe230aea9d5cfb76.h5.lock\n",
            "2021-04-18 19:45:44 filelock INFO: Lock 140139546855376 acquired on /root/.cache/huggingface/transformers/01800f4158e284e2447020e0124bc3f6aea3ac49848e744594f7cce8ee5ac0a4.a7137b2090d9302d722735af604b4c142ec9d1bfc31be7cbbe230aea9d5cfb76.h5.lock\n",
            "2021-04-18 19:45:44 urllib3.connectionpool DEBUG: Starting new HTTPS connection (1): cdn-lfs.huggingface.co:443\n",
            "2021-04-18 19:45:44 urllib3.connectionpool DEBUG: https://cdn-lfs.huggingface.co:443 \"GET /bert-base-cased/0d04ece69d04b890153ea3bd5c2ef5706f9181495a0778a2593c6118f7ce2dc3 HTTP/1.1\" 200 526681800\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95e8f217619943abab4fdb718c8ed667",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=526681800.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 19:45:53 filelock DEBUG: Attempting to release lock 140139546855376 on /root/.cache/huggingface/transformers/01800f4158e284e2447020e0124bc3f6aea3ac49848e744594f7cce8ee5ac0a4.a7137b2090d9302d722735af604b4c142ec9d1bfc31be7cbbe230aea9d5cfb76.h5.lock\n",
            "2021-04-18 19:45:53 filelock INFO: Lock 140139546855376 released on /root/.cache/huggingface/transformers/01800f4158e284e2447020e0124bc3f6aea3ac49848e744594f7cce8ee5ac0a4.a7137b2090d9302d722735af604b4c142ec9d1bfc31be7cbbe230aea9d5cfb76.h5.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtkcZjqbfjB1"
      },
      "source": [
        "FULL_FINETUNING = True\n",
        "if False:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsa-6q5yfsRh"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 10\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "# total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# scheduler = get_linear_schedule_with_warmup(\n",
        "#     optimizer,\n",
        "#     num_warmup_steps=0\n",
        "#     num_training_steps=total_steps\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmzOQvwWgOnG"
      },
      "source": [
        "import keras\n",
        "optimizer = keras.optimizers.Adam(lr=3e-5)\n",
        "# Loss\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Compile\n",
        "model.compile(loss=loss,\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "# Learning Rate Scheduler: Change learning rates during training epochs\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * 0.01\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "# Early Stopping: Stop training when a monitored metric has stopped improving\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto'\n",
        ")\n",
        "callbacks = [lr_scheduler,early_stopping]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgwSUpdhgEVV",
        "outputId": "8d1d449e-ea6d-4c62-ca6f-6e539af03870"
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "training_results = model.fit(\n",
        "        train_data,\n",
        "        validation_data=val_data,\n",
        "        epochs=epochs, \n",
        "        callbacks=callbacks,\n",
        "        verbose=1)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 20:06:52 tensorflow WARNING: The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 20:06:52 tensorflow WARNING: The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 20:06:58 tensorflow WARNING: The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 20:06:58 tensorflow WARNING: The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1349/1349 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9881WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 20:09:54 tensorflow WARNING: The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 20:09:54 tensorflow WARNING: The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1349/1349 [==============================] - 192s 130ms/step - loss: 0.0357 - accuracy: 0.9881 - val_loss: 0.0694 - val_accuracy: 0.9803\n",
            "Epoch 2/10\n",
            "1349/1349 [==============================] - 173s 128ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0741 - val_accuracy: 0.9808\n",
            "Epoch 3/10\n",
            "1349/1349 [==============================] - 173s 128ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.0814 - val_accuracy: 0.9807\n",
            "Epoch 4/10\n",
            "1349/1349 [==============================] - 173s 128ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0825 - val_accuracy: 0.9811\n",
            "Training execution time (mins) 11.8635982076327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPkLAxpCkTrd",
        "outputId": "2f057ee1-8431-4169-cd3d-055da551c503"
      },
      "source": [
        "bert_logit = model.predict(val_data)\n",
        "bert_pred = bert_logit[0].argmax(axis=2).flatten()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 20:18:44 tensorflow WARNING: The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 20:18:44 tensorflow WARNING: The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4SRCQzRlYr4",
        "outputId": "84798bd1-9994-42ca-ed4c-a141ef56f117"
      },
      "source": [
        "f1 = f1_score(te_tags.numpy().flatten(), bert_pred, average = None)\n",
        "print(pd.DataFrame(f1, index = tags))\n",
        "print('Mean F1 across classes: ',np.mean(f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              0\n",
            "B-art  0.169935\n",
            "B-eve  0.314286\n",
            "B-geo  0.889625\n",
            "B-gpe  0.946950\n",
            "B-nat  0.205128\n",
            "B-org  0.767917\n",
            "B-per  0.850000\n",
            "B-tim  0.883441\n",
            "I-art  0.068966\n",
            "I-eve  0.382353\n",
            "I-geo  0.808559\n",
            "I-gpe  0.722222\n",
            "I-nat  0.400000\n",
            "I-org  0.760237\n",
            "I-per  0.886698\n",
            "I-tim  0.798046\n",
            "O      0.990768\n",
            "PAD    1.000000\n",
            "Mean F1 across classes:  0.6580627695777646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4YyTqSto5Ux"
      },
      "source": [
        "### Entity Level F-1 for BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GffNIhrYpA7S"
      },
      "source": [
        "bert_pred = bert_logit[0].argmax(axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tigVlw10rNUs"
      },
      "source": [
        "bert_pred_tag = []\n",
        "y_true_tag = []\n",
        "y_true_te = te_tags.numpy()\n",
        "\n",
        "for i in range(len(bert_pred)):\n",
        "  bert_pred_tag.append(list(map(idx2tag.get, bert_pred[i])))\n",
        "  y_true_tag.append(list(map(idx2tag.get, y_true_te[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEZyp1ts-06"
      },
      "source": [
        "entity_tag = ['art', 'eve', 'geo', 'gpe', 'nat', 'org', 'per', 'tim']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYWJTJ0ypkzm"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "metrics_results = {'correct': 0, 'incorrect': 0, 'partial': 0,\n",
        "                   'missed': 0, 'spurious': 0, 'possible': 0, 'actual': 0, 'precision': 0,'recall': 0,}\n",
        "\n",
        "# overall results\n",
        "results = {'strict': deepcopy(metrics_results),\n",
        "           'ent_type': deepcopy(metrics_results),\n",
        "           \n",
        "           }\n",
        "\n",
        "# results aggregated by entity type\n",
        "evaluation_agg_entities_type = {e: deepcopy(results) for e in entity_tag}\n",
        "\n",
        "for true_ents, pred_ents in zip(y_true_tag, bert_pred_tag):    \n",
        "    # compute results for one message\n",
        "    tmp_results, tmp_agg_results = compute_metrics(collect_named_entities(true_ents),collect_named_entities(pred_ents), entity_tag)\n",
        "\n",
        "    # aggregate overall results\n",
        "    for eval_schema in results.keys():\n",
        "        for metric in metrics_results.keys():\n",
        "            results[eval_schema][metric] += tmp_results[eval_schema][metric]\n",
        "\n",
        "\n",
        "    # aggregate results by entity type\n",
        "    for e_type in entity_tag:\n",
        "        for eval_schema in evaluation_agg_entities_type[e_type]:\n",
        "            for metric in tmp_agg_results[e_type][eval_schema]:\n",
        "                evaluation_agg_entities_type[e_type][eval_schema][metric] += tmp_agg_results[e_type][eval_schema][metric]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prxCAgactuc0",
        "outputId": "cc3de96e-11bb-446d-e0ae-dd1b817da023"
      },
      "source": [
        "make_precision_recall(evaluation_agg_entities_type,'strict')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'art': {'f1': 0.01827875095201828,\n",
              "  'precision': 0.009828009828009828,\n",
              "  'recall': 0.13043478260869565},\n",
              " 'eve': {'f1': 0.014481094127111826,\n",
              "  'precision': 0.0075,\n",
              "  'recall': 0.20930232558139536},\n",
              " 'geo': {'f1': 0.8487229862475443,\n",
              "  'precision': 0.7918781725888325,\n",
              "  'recall': 0.914360143275806},\n",
              " 'gpe': {'f1': 0.7043918918918919,\n",
              "  'precision': 0.5652321247034904,\n",
              "  'recall': 0.934453781512605},\n",
              " 'nat': {'f1': 0.008244023083264633,\n",
              "  'precision': 0.004205214465937763,\n",
              "  'recall': 0.20833333333333334},\n",
              " 'org': {'f1': 0.6276712663328856,\n",
              "  'precision': 0.5687098915689311,\n",
              "  'recall': 0.7002724795640327},\n",
              " 'per': {'f1': 0.6946272769018828,\n",
              "  'precision': 0.6050666666666666,\n",
              "  'recall': 0.8153072224218469},\n",
              " 'tim': {'f1': 0.7115384615384616,\n",
              "  'precision': 0.6052217678515256,\n",
              "  'recall': 0.8631673396141768}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    }
  ]
}